---
title: "Pr系系mpt: Sanitizing Sensitive Prompts for LLMs"
collection: publications
permalink: /publication/2023-12-26-preempt-ppai
excerpt: 'We introduce a cryptographically inspired notion of a prompt sanitizer which transforms an input prompt to protect its sensitive tokens.'
date: 2023-12-26
venue: 'AAAI 2024 Workshop (Privacy-Preserving Artificial Intelligence)'
---
In this paper, we address the problem of formally protecting the sensitive information contained in a prompt while maintaining response quality. To this end, first, we introduce a cryptographically inspired notion of a prompt sanitizer which transforms an input prompt to protect its sensitive tokens. Our evaluation demonstrates that Pr系系mpt is a practical method to achieve meaningful privacy guarantees, while maintaining high utility compared to unsanitized prompts, and outperforming prior methods.

[[Paper](https://www.cs.toronto.edu/~dglukhov/Preempt.pdf)]

<!-- Recommended citation: Your Name, You. (2015). "Paper Title Number 3." <i>Journal 1</i>. 1(3). -->
